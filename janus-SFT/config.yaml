wandb:
  entity: null
  resume: auto
  run_id: nrrt3rj8
experiment:
  project: janus-SFT
  name: janus-SFT
  output_dir: janus-SFT
  max_train_examples: 20000000
  max_train_examples_mmu: 40000000
  save_every: 10000
  eval_every: 2500
  generate_every: 1000
  log_every: 50
  log_grad_norm_every: 500
  resume_from_checkpoint: latest
  logging_dir: janus-SFT/logs
model:
  janus_pro:
    model_name_or_path: deepseek-ai/Janus-Pro-7B
  gradient_checkpointing: true
dataset:
  params:
    path: /home/v-haodongli/Janus/tmp_script/laion_2b_aesthetic
    shuffle_buffer_size: 1000
    max_samples: 1000
    num_workers: 24
    resolution: 256
    pin_memory: true
    persistent_workers: true
  preprocessing:
    max_seq_length: 381
optimizer:
  name: adamw
  params:
    learning_rate: 2.0e-05
    scale_lr: false
    beta1: 0.9
    beta2: 0.999
    weight_decay: 0.01
    epsilon: 1.0e-08
lr_scheduler:
  scheduler: cosine
  params:
    learning_rate: ${optimizer.params.learning_rate}
    warmup_steps: 1000
training:
  gradient_accumulation_steps: 1
  noise_type: mask
  batch_size: 4
  samples_per_epoch: 10000
  mixed_precision: bf16
  enable_tf32: true
  seed: 10086
  max_train_steps: 10000
  overfit_one_batch: false
  cond_dropout_prob: 0.1
  min_masking_rate: 0.0
  label_smoothing: 0.0
  max_grad_norm: null
  guidance_scale: 0.0
  generation_timesteps: 12
  t2i_coeff: 1.0
  lm_coeff: 0.1
  mmu_coeff: 1.0
config: config/sft.yaml

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ptca/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import copy\n",
    "from dataclasses import dataclass, field\n",
    "import json\n",
    "import logging\n",
    "import pathlib\n",
    "from typing import Dict, Optional, Sequence, List\n",
    "import time\n",
    "import torch, gc\n",
    "import glob\n",
    "import transformers\n",
    "import tokenizers\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image, ImageFile\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from pathlib import Path\n",
    "from datasets.utils.logging import set_verbosity_info\n",
    "from transformers import logging as tf_logging\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from transformers import AutoProcessor\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sample(sample):\n",
    "    try:\n",
    "        metadata = sample[\"json\"]\n",
    "        return {\n",
    "            \"caption\": metadata.get(\"caption\"),\n",
    "            \"cot\": metadata.get(\"cot\"),\n",
    "            \"aspect_ratio\": metadata.get(\"aspect_ratio\"),\n",
    "            \"img_index\": metadata.get(\"img_index\")\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing sample: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from datasets import concatenate_datasets\n",
    "import glob\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "\n",
    "class LazySupervisedMixDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: str,\n",
    "        processor: AutoProcessor,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data_files = glob.glob(os.path.join(data_path, \"*.tar\"))  # 保存 tar 文件列表\n",
    "        train_datasets = []\n",
    "        self.offsets = [0]  # 记录每个 tar 文件的起始索引\n",
    "\n",
    "        # 逐个加载并处理 tar 文件\n",
    "        for data_file in self.data_files:\n",
    "            raw_dataset = load_dataset(\"webdataset\", data_files=[data_file], split=\"train\", num_proc=128)\n",
    "            train_dataset = raw_dataset.map(process_sample).filter(lambda x: x is not None)\n",
    "            train_datasets.append(train_dataset)\n",
    "            self.offsets.append(self.offsets[-1] + len(train_dataset))  # 累积样本数\n",
    "\n",
    "        # 合并数据集\n",
    "        if len(train_datasets) > 1:\n",
    "            self.list_data_dict = concatenate_datasets(train_datasets)\n",
    "        else:\n",
    "            self.list_data_dict = train_datasets[0]\n",
    "\n",
    "        self.processor = processor\n",
    "\n",
    "    # def process_sample(self, sample):\n",
    "    #     # 示例处理逻辑，确保返回有效样本\n",
    "    #     if 'caption' not in sample or 'cot' not in sample:\n",
    "    #         return None\n",
    "    #     return sample\n",
    "\n",
    "    def get_tar_info(self, index: int):\n",
    "        \"\"\"根据全局索引定位到 tar 文件和文件内偏移量\"\"\"\n",
    "        for i in range(len(self.offsets) - 1):\n",
    "            if self.offsets[i] <= index < self.offsets[i + 1]:\n",
    "                tar_index = i  # tar 文件索引\n",
    "                file_index = index - self.offsets[i]  # 文件内偏移量\n",
    "                return self.data_files[tar_index], file_index\n",
    "        raise IndexError(f\"Index {index} out of range\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_data_dict)\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        sources = self.list_data_dict[i]\n",
    "\n",
    "        conversation = [\n",
    "            {\"role\": \"<|User|>\", \"content\": sources['caption']},\n",
    "            {\"role\": \"<|Assistant|>\", \"content\": f\"{sources['cot']}<begin_of_image><end_of_image>\"},\n",
    "        ]\n",
    "        system_prompt = \"You are an assistant that creates images from descriptions. First, describe the image in detail, then generate it.\"\n",
    "        prompt = self.processor.apply_sft_template_for_multi_turn_prompts(\n",
    "            conversations=conversation,\n",
    "            sft_format=self.processor.sft_format,\n",
    "            system_prompt=system_prompt,\n",
    "        )\n",
    "\n",
    "        # Tokenize prompt\n",
    "        text_ids = self.processor.tokenizer.encode(prompt)\n",
    "        all_ids = text_ids[:-2] + sources['img_index'] + text_ids[-2:]\n",
    "        all_ids = torch.LongTensor(all_ids)\n",
    "\n",
    "        # 构建图像 token 的 mask\n",
    "        all_image_ids_mask = torch.zeros(all_ids.shape, dtype=torch.bool)\n",
    "        all_image_ids_mask[-len(sources['img_index'])-2:-2] = True\n",
    "\n",
    "        # 找到 Assistant 回答开始的位置\n",
    "        try:\n",
    "            assistant_start_token_id = self.processor.tokenizer.encode(\"<|Assistant|>\")[0]\n",
    "            assistant_start_index = text_ids.index(assistant_start_token_id)\n",
    "        except (ValueError, IndexError):\n",
    "            assistant_start_index = 0\n",
    "\n",
    "        assistant_ids_mask = torch.zeros(all_ids.shape, dtype=torch.bool)\n",
    "        assistant_ids_mask[assistant_start_index:] = True\n",
    "\n",
    "        # 构造输入和标签\n",
    "        input_ids = all_ids[:-1]\n",
    "        text_ids_mask = (all_image_ids_mask[:-1] == False)\n",
    "        image_ids_mask = all_image_ids_mask[:-1]\n",
    "        label_ids = all_ids[1:]\n",
    "        label_text_ids_mask = assistant_ids_mask[1:] & (all_image_ids_mask[1:] == False)\n",
    "        label_image_ids_mask = assistant_ids_mask[1:] & all_image_ids_mask[1:]\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"label_ids\": label_ids,\n",
    "            \"text_ids_mask\": text_ids_mask,\n",
    "            \"image_ids_mask\": image_ids_mask,\n",
    "            \"label_text_ids_mask\": label_text_ids_mask,\n",
    "            \"label_image_ids_mask\": label_image_ids_mask,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version is above 3.10, patching the collections module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py:609: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16384\n",
      "Padding ID: 100015\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m padding_id \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mpad_token_id\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPadding ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpadding_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mLazySupervisedMixDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/mnt/v-haodongli/cot_output_test_train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 22\u001b[0m, in \u001b[0;36mLazySupervisedMixDataset.__init__\u001b[0;34m(self, data_path, processor)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# 逐个加载并处理 tar 文件\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data_file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_files:\n\u001b[0;32m---> 22\u001b[0m     raw_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwebdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mdata_file\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m raw_dataset\u001b[38;5;241m.\u001b[39mmap(process_sample)\u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;28;01mlambda\u001b[39;00m x: x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m     train_datasets\u001b[38;5;241m.\u001b[39mappend(train_dataset)\n",
      "File \u001b[0;32m/opt/conda/envs/ptca/lib/python3.10/site-packages/datasets/load.py:2062\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2057\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[1;32m   2058\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[1;32m   2059\u001b[0m )\n\u001b[1;32m   2061\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 2062\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2075\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2076\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2077\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2079\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   2080\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m/opt/conda/envs/ptca/lib/python3.10/site-packages/datasets/load.py:1782\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     download_config \u001b[38;5;241m=\u001b[39m download_config\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[1;32m   1781\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mstorage_options\u001b[38;5;241m.\u001b[39mupdate(storage_options)\n\u001b[0;32m-> 1782\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_custom_configs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[1;32m   1795\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[0;32m/opt/conda/envs/ptca/lib/python3.10/site-packages/datasets/load.py:1491\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1474\u001b[0m \u001b[38;5;66;03m# We have several ways to get a dataset builder:\u001b[39;00m\n\u001b[1;32m   1475\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;66;03m# - if path is the name of a packaged dataset module\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1488\u001b[0m \n\u001b[1;32m   1489\u001b[0m \u001b[38;5;66;03m# Try packaged\u001b[39;00m\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m _PACKAGED_DATASETS_MODULES:\n\u001b[0;32m-> 1491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPackagedDatasetModuleFactory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_module()\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;66;03m# Try locally\u001b[39;00m\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mendswith(filename):\n",
      "File \u001b[0;32m/opt/conda/envs/ptca/lib/python3.10/site-packages/datasets/load.py:904\u001b[0m, in \u001b[0;36mPackagedDatasetModuleFactory.__init__\u001b[0;34m(self, name, data_dir, data_files, download_config, download_mode)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_config \u001b[38;5;241m=\u001b[39m download_config\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_mode \u001b[38;5;241m=\u001b[39m download_mode\n\u001b[0;32m--> 904\u001b[0m \u001b[43mincrease_load_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ptca/lib/python3.10/site-packages/datasets/load.py:287\u001b[0m, in \u001b[0;36mincrease_load_count\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mHF_HUB_OFFLINE \u001b[38;5;129;01mand\u001b[39;00m config\u001b[38;5;241m.\u001b[39mHF_UPDATE_DOWNLOAD_COUNTS:\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 287\u001b[0m         \u001b[43mget_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mS3_DATASETS_BUCKET_PREFIX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUser-Agent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_datasets_user_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    293\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/ptca/lib/python3.10/site-packages/requests/sessions.py:624\u001b[0m, in \u001b[0;36mSession.head\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a HEAD request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \n\u001b[1;32m    618\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    623\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 624\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ptca/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/conda/envs/ptca/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/conda/envs/ptca/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:96\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSend: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_curlify(request)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     request_id \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001b[0;32m/opt/conda/envs/ptca/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/opt/conda/envs/ptca/lib/python3.10/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/ptca/lib/python3.10/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/opt/conda/envs/ptca/lib/python3.10/site-packages/urllib3/connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/opt/conda/envs/ptca/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/envs/ptca/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/ptca/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/ptca/lib/python3.10/socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/ptca/lib/python3.10/ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/conda/envs/ptca/lib/python3.10/ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from janus.models.processing_vlm import VLChatProcessor\n",
    "processor: VLChatProcessor = VLChatProcessor.from_pretrained(\"deepseek-ai/Janus-Pro-7B\")\n",
    "tokenizer = processor.tokenizer\n",
    "print(tokenizer.model_max_length)\n",
    "padding_id = tokenizer.pad_token_id\n",
    "print(f\"Padding ID: {padding_id}\")\n",
    "train_dataset = LazySupervisedMixDataset(data_path=\"/mnt/v-haodongli/cot_output_test_train\", processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_file, file_index = train_dataset.get_tar_info(2132052)\n",
    "print(f\"索引 2132052 的数据位于 tar 文件: {tar_file}，文件内第 {file_index} 个样本\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webdataset as wds\n",
    "\n",
    "shard_path = '/mnt/v-haodongli/cot_output_test_train/02166.tar'\n",
    "target_key = \"02166_00028\"  # 想看的 key\n",
    "\n",
    "dataset = wds.WebDataset(shard_path).decode().to_tuple(\"__key__\", \"json\")\n",
    "\n",
    "for key, label in dataset:\n",
    "    if key == target_key:\n",
    "        print(\"Key:\", key)\n",
    "        print(\"Label:\", label)\n",
    "        break  # 找到后退出循环   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_dataset[1]\n",
    "len(sample[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_dataset)):\n",
    "    try:\n",
    "        sample = train_dataset[i]\n",
    "        if len(sample['input_ids'])>2000:\n",
    "            print(f\"Sample index {i}: input_ids length = {len(sample['input_ids'])}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error at index {i}: {e}\")\n",
    "        # 打印原始数据源信息\n",
    "        print(\"Raw data:\", train_dataset.data[i])\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 2010347\n",
    "for i in range(start_index, len(train_dataset)):\n",
    "    try:\n",
    "        sample = train_dataset[i]\n",
    "        if len(sample['input_ids']) > 2000:  # 检查 input_ids 长度\n",
    "            print(f\"Sample index {i}: input_ids length = {len(sample['input_ids'])}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error at index {i}: {e}\")  # 打印错误信息\n",
    "        print(\"Raw data:\", train_dataset.data[i])  # 打印原始数据（需确保 data 属性存在）\n",
    "        continue  # 跳过当前错误样本，继续循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 2132053\n",
    "for i in range(start_index, len(train_dataset)):\n",
    "    try:\n",
    "        sample = train_dataset[i]\n",
    "        if len(sample['input_ids']) > 2000:  # 检查 input_ids 长度\n",
    "            print(f\"Sample index {i}: input_ids length = {len(sample['input_ids'])}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error at index {i}: {e}\")  # 打印错误信息\n",
    "        print(\"Raw data:\", train_dataset.data[i])  # 打印原始数据（需确保 data 属性存在）\n",
    "        continue  # 跳过当前错误样本，继续循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webdataset as wds\n",
    "import os\n",
    "\n",
    "# 输入路径（同时也是目标输出路径）\n",
    "input_shard = '/mnt/v-haodongli/cot_output_test_train/02166.tar'\n",
    "\n",
    "# 临时中间文件路径\n",
    "temp_shard = input_shard + \".tmp\"\n",
    "\n",
    "# 想要删除的 key\n",
    "target_key_to_remove = \"02166_00027\"\n",
    "\n",
    "# 第一步：读取原始 tar，过滤后写入临时文件\n",
    "with wds.TarWriter(temp_shard) as sink:\n",
    "    with wds.WebDataset(input_shard) as dataset:\n",
    "        for sample in dataset:\n",
    "            if sample[\"__key__\"] == target_key_to_remove:\n",
    "                print(f\"Skipping key: {target_key_to_remove}\")\n",
    "                continue\n",
    "            sink.write(sample)\n",
    "\n",
    "# 第二步：将临时文件替换回原文件名（覆盖原文件）\n",
    "os.replace(temp_shard, input_shard)\n",
    "\n",
    "print(f\"Done. Removed key '{target_key_to_remove}' and overwritten the original file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in the saved file:\n",
      "dict_keys(['batch', 'global_step', 'input_ids', 'text_id_mask', 'image_id_mask', 'label_ids', 'label_text_id_mask', 'label_image_id_mask'])\n",
      "\n",
      "Data details:\n",
      "batch: <class 'dict'>\n",
      "  input_ids: torch.Size([4, 1176]) | dtype: torch.int64\n",
      "  label_ids: torch.Size([4, 1176]) | dtype: torch.int64\n",
      "  attention_mask: torch.Size([4, 1176]) | dtype: torch.bool\n",
      "  text_id_mask: torch.Size([4, 1176]) | dtype: torch.bool\n",
      "  image_id_mask: torch.Size([4, 1176]) | dtype: torch.bool\n",
      "  label_text_id_mask: torch.Size([4, 1176]) | dtype: torch.bool\n",
      "  label_image_id_mask: torch.Size([4, 1176]) | dtype: torch.bool\n",
      "global_step: <class 'int'>\n",
      "  Value: 326\n",
      "input_ids: torch.Size([4, 1176]) | dtype: torch.int64\n",
      "text_id_mask: torch.Size([4, 1176]) | dtype: torch.bool\n",
      "image_id_mask: torch.Size([4, 1176]) | dtype: torch.bool\n",
      "label_ids: torch.Size([4, 1176]) | dtype: torch.int64\n",
      "label_text_id_mask: torch.Size([4, 1176]) | dtype: torch.bool\n",
      "label_image_id_mask: torch.Size([4, 1176]) | dtype: torch.bool\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 文件路径\n",
    "file_path = \"/scratch/amlt_code/debug_batch_step_327_rank_3.pt\"\n",
    "\n",
    "# 加载文件\n",
    "data = torch.load(file_path, map_location='cpu')  # 建议先加载到 CPU 上\n",
    "\n",
    "# 打印所有 key\n",
    "print(\"Keys in the saved file:\")\n",
    "print(data.keys())\n",
    "\n",
    "# 打印每个 key 对应的数据形状或内容\n",
    "print(\"\\nData details:\")\n",
    "for key, value in data.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(f\"{key}: {value.shape} | dtype: {value.dtype}\")\n",
    "    else:\n",
    "        print(f\"{key}: {type(value)}\")\n",
    "        if isinstance(value, dict):\n",
    "            for k, v in value.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    print(f\"  {k}: {v.shape} | dtype: {v.dtype}\")\n",
    "                else:\n",
    "                    print(f\"  {k}: {type(v)}\")\n",
    "        else:\n",
    "            print(f\"  Value: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ids = data[\"label_ids\"]\n",
    "label_text_ids_mask = data[\"label_text_id_mask\"]\n",
    "input_ids = data[\"input_ids\"]\n",
    "image_ids_mask = data[\"image_id_mask\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = processor.tokenizer.decode(label_ids[label_text_ids_mask], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an assistant that creates images from descriptions. First, describe the image in detail, then generate it.\\n\\n<|User|>: Valentines table runner\\n\\n<|Assistant|>: A Valentine\\'s table runner is displayed. It is rectangular in shape, with a red and white color scheme. The runner is composed of numerous small squares, each featuring a heart design. The hearts are red and white, with some having a three-dimensional texture. The squares are arranged in a grid pattern, creating a patchwork effect. The table runner is placed on a wooden surface, which is partially visible at the top and bottom edges of the image. The style of the image is a close-up photograph, focusing on the intricate details of the table runner.<begin_of_image><end_of_image><｜end▁of▁sentence｜>You are an assistant that creates images from descriptions. First, describe the image in detail, then generate it.\\n\\n<|User|>: The Coolest Cars In Racing Game History\\n\\n<|Assistant|>: The image depicts a racing game interface featuring a green and white sports car, the Viper Venom 1000. The car is shown in a dynamic pose, suggesting speed and motion. The background is a blurred cityscape, indicating the car is in motion. The interface includes various game statistics and information:\\n\\n- A blue bar at the top left corner, likely representing the player\\'s health or energy.\\n- A blue bar at the top right corner, possibly indicating the player\\'s speed or another game metric.\\n- A shield icon with the text \"Viper Venom 1000\" below it, indicating the car\\'s name.\\n- A list of attributes for the car: \"Мощность\" (Power), \"Скорость\" (Speed), and \"Управляемость\" (Handling).\\n- A blue bar at the bottom left corner, possibly representing the player\\'s current speed or another game metric.\\n- A blue bar at the bottom right corner, possibly indicating the player\\'s position in the race.\\n- A blue bar at the bottom center, possibly representing the player\\'s current speed or another game metric.\\n- A blue bar at the bottom center, possibly representing the player\\'s current speed or another game metric.\\n- A blue bar at the bottom center, possibly representing the player\\'s current speed or another game metric.\\n- A blue bar at the bottom center, possibly representing the player\\'s current speed or another game metric.\\n- A blue bar at the bottom center, possibly representing the player\\'s current speed or another game metric.\\n- A blue bar at the bottom center, possibly representing the player\\'s current speed or another game metric.\\n- A blue bar at the bottom center, possibly representing the player\\'s current speed or another game metric.\\n- A blue bar at the bottom center, possibly representing the player\\'s current speed or another game metric.\\n- A blue bar at the bottom center, possibly representing the player\\'s current speed or another game metric.\\n- A blue bar at the bottom center, possibly representing the player\\'s current speed or another game metric.\\n- A blue bar at the bottom center, possibly representing the player\\'s current speed or another game metric.\\n- A blue bar at the bottom center, possibly representing the player\\'s current speed or another game metric.\\n- A blue bar at the bottom center, possibly representing the player\\'s current speed or another game metric.\\n- A blue bar at the bottom center, possibly representing the player\\'s current speed or another game metric.\\n- A blue bar at the bottom center, possibly representing the<begin_of_image><end_of_image><｜end▁of▁sentence｜>You are an assistant that creates images from descriptions. First, describe the image in detail, then generate it.\\n\\n<|User|>: Check out the megayacht-filled Port de Monaco, where billionaires go to play.\\n\\n<|Assistant|>: The image depicts a picturesque harbor, Port de Monaco, filled with numerous megayachts. The yachts are docked in a bay surrounded by a rocky cliff. The harbor is nestled between the cliff and the sea, with a clear blue sky above. The yachts vary in size and color, with some appearing white and others in shades of blue and green. The cliff is covered with greenery, and there are buildings perched on the top of the cliff, overlooking the harbor. The sea is a vibrant blue, and the overall scene is bathed in sunlight, creating a serene and luxurious atmosphere. The style of the image is a high-resolution aerial photograph, capturing the beauty and opulence of the harbor.<begin_of_image><end_of_image><｜end▁of▁sentence｜>You are an assistant that creates images from descriptions. First, describe the image in detail, then generate it.\\n\\n<|User|>: My favorite fire pits {and why} via interior designer @fieldstonehill\\n\\n<|Assistant|>: The image shows a serene lakeside setting with a fire pit as the focal point. The fire pit is surrounded by a circular arrangement of red Adirondack chairs, each with a cushion. The chairs are positioned on a gravel base, which encircles the fire pit. The fire pit itself is made of stones and contains a small fire with smoke rising. A few items, including a cooler and a blanket, are placed around the fire pit. In the background, there is a grassy area leading to a dock where a small boat is moored. The water is calm, reflecting the sky, and the overall scene is bathed in the warm light of either sunrise or sunset. The style of the image is natural and inviting, emphasizing relaxation and outdoor enjoyment.<begin_of_image><end_of_image><｜end▁of▁sentence｜>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def decode_to_pil(vq_list, vl_gpt, shape=(1, 8, 24, 24)):\n",
    "    # 将列表转为张量并移动到GPU\n",
    "    vq_tensor = torch.tensor(vq_list, dtype=torch.int, device=\"cuda\")\n",
    "    print(vq_tensor.shape)\n",
    "    # 解码图像数据（假设vl_gpt已加载）\n",
    "    with torch.no_grad():\n",
    "        dec = vl_gpt.gen_vision_model.decode_code(vq_tensor, shape=shape)\n",
    "    \n",
    "    # 后处理：张量转图像\n",
    "    dec = dec.to(torch.float32).cpu().numpy().transpose(0, 2, 3, 1)\n",
    "    dec = np.clip((dec + 1) / 2 * 255, 0, 255).astype(np.uint8)\n",
    "    return Image.fromarray(dec[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2304])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 24, 24, 8]' is invalid for input of size 18432",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjanus\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_vlm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiModalityCausalLM\n\u001b[1;32m      2\u001b[0m model: MultiModalityCausalLM \u001b[38;5;241m=\u001b[39m MultiModalityCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepseek-ai/Janus-Pro-7B\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m         trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_to_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimage_ids_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m, in \u001b[0;36mdecode_to_pil\u001b[0;34m(vq_list, vl_gpt, shape)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 解码图像数据（假设vl_gpt已加载）\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 8\u001b[0m     dec \u001b[38;5;241m=\u001b[39m \u001b[43mvl_gpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_vision_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvq_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 后处理：张量转图像\u001b[39;00m\n\u001b[1;32m     11\u001b[0m dec \u001b[38;5;241m=\u001b[39m dec\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/scratch/amlt_code/janus/models/vq_model.py:506\u001b[0m, in \u001b[0;36mVQModel.decode_code\u001b[0;34m(self, code_b, shape, channel_first)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode_code\u001b[39m(\u001b[38;5;28mself\u001b[39m, code_b, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, channel_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 506\u001b[0m     quant_b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_codebook_entry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m     dec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(quant_b)\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dec\n",
      "File \u001b[0;32m/scratch/amlt_code/janus/models/vq_model.py:294\u001b[0m, in \u001b[0;36mVectorQuantizer.get_codebook_entry\u001b[0;34m(self, indices, shape, channel_first)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m channel_first:\n\u001b[0;32m--> 294\u001b[0m         z_q \u001b[38;5;241m=\u001b[39m \u001b[43mz_q\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;66;03m# reshape back to match original input shape\u001b[39;00m\n\u001b[1;32m    296\u001b[0m         z_q \u001b[38;5;241m=\u001b[39m z_q\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 24, 24, 8]' is invalid for input of size 18432"
     ]
    }
   ],
   "source": [
    "from janus.models.modeling_vlm import MultiModalityCausalLM\n",
    "model: MultiModalityCausalLM = MultiModalityCausalLM.from_pretrained(\n",
    "        \"deepseek-ai/Janus-Pro-7B\",\n",
    "        trust_remote_code=True).to(\"cuda\")\n",
    "image = decode_to_pil(input_ids[image_ids_mask].tolist(), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in the saved file:\n",
      "dict_keys(['batch', 'global_step', 'input_ids', 'text_id_mask', 'image_id_mask', 'label_ids', 'label_text_id_mask', 'label_image_id_mask'])\n",
      "\n",
      "Data details:\n",
      "batch: <class 'dict'>\n",
      "  input_ids: torch.Size([4, 780]) | dtype: torch.int64\n",
      "  label_ids: torch.Size([4, 780]) | dtype: torch.int64\n",
      "  attention_mask: torch.Size([4, 780]) | dtype: torch.bool\n",
      "  text_id_mask: torch.Size([4, 780]) | dtype: torch.bool\n",
      "  image_id_mask: torch.Size([4, 780]) | dtype: torch.bool\n",
      "  label_text_id_mask: torch.Size([4, 780]) | dtype: torch.bool\n",
      "  label_image_id_mask: torch.Size([4, 780]) | dtype: torch.bool\n",
      "global_step: <class 'int'>\n",
      "  Value: 1\n",
      "input_ids: torch.Size([4, 780]) | dtype: torch.int64\n",
      "text_id_mask: torch.Size([4, 780]) | dtype: torch.bool\n",
      "image_id_mask: torch.Size([4, 780]) | dtype: torch.bool\n",
      "label_ids: torch.Size([4, 780]) | dtype: torch.int64\n",
      "label_text_id_mask: torch.Size([4, 780]) | dtype: torch.bool\n",
      "label_image_id_mask: torch.Size([4, 780]) | dtype: torch.bool\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 文件路径\n",
    "file_path = \"/scratch/amlt_code/debug_batch_step_2_rank_3.pt\"\n",
    "\n",
    "# 加载文件\n",
    "data = torch.load(file_path, map_location='cpu')  # 建议先加载到 CPU 上\n",
    "\n",
    "# 打印所有 key\n",
    "print(\"Keys in the saved file:\")\n",
    "print(data.keys())\n",
    "\n",
    "# 打印每个 key 对应的数据形状或内容\n",
    "print(\"\\nData details:\")\n",
    "for key, value in data.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(f\"{key}: {value.shape} | dtype: {value.dtype}\")\n",
    "    else:\n",
    "        print(f\"{key}: {type(value)}\")\n",
    "        if isinstance(value, dict):\n",
    "            for k, v in value.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    print(f\"  {k}: {v.shape} | dtype: {v.dtype}\")\n",
    "                else:\n",
    "                    print(f\"  {k}: {type(v)}\")\n",
    "        else:\n",
    "            print(f\"  Value: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ids = data[\"label_ids\"]\n",
    "label_text_ids_mask = data[\"label_text_id_mask\"]\n",
    "input_ids = data[\"input_ids\"]\n",
    "image_ids_mask = data[\"image_id_mask\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2304])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 24, 24, 8]' is invalid for input of size 18432",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjanus\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_vlm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiModalityCausalLM\n\u001b[1;32m      2\u001b[0m model: MultiModalityCausalLM \u001b[38;5;241m=\u001b[39m MultiModalityCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepseek-ai/Janus-Pro-7B\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m         trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_to_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimage_ids_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m, in \u001b[0;36mdecode_to_pil\u001b[0;34m(vq_list, vl_gpt, shape)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 解码图像数据（假设vl_gpt已加载）\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 8\u001b[0m     dec \u001b[38;5;241m=\u001b[39m \u001b[43mvl_gpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_vision_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvq_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 后处理：张量转图像\u001b[39;00m\n\u001b[1;32m     11\u001b[0m dec \u001b[38;5;241m=\u001b[39m dec\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/scratch/amlt_code/janus/models/vq_model.py:506\u001b[0m, in \u001b[0;36mVQModel.decode_code\u001b[0;34m(self, code_b, shape, channel_first)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode_code\u001b[39m(\u001b[38;5;28mself\u001b[39m, code_b, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, channel_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 506\u001b[0m     quant_b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_codebook_entry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m     dec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(quant_b)\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dec\n",
      "File \u001b[0;32m/scratch/amlt_code/janus/models/vq_model.py:294\u001b[0m, in \u001b[0;36mVectorQuantizer.get_codebook_entry\u001b[0;34m(self, indices, shape, channel_first)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m channel_first:\n\u001b[0;32m--> 294\u001b[0m         z_q \u001b[38;5;241m=\u001b[39m \u001b[43mz_q\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;66;03m# reshape back to match original input shape\u001b[39;00m\n\u001b[1;32m    296\u001b[0m         z_q \u001b[38;5;241m=\u001b[39m z_q\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 24, 24, 8]' is invalid for input of size 18432"
     ]
    }
   ],
   "source": [
    "from janus.models.modeling_vlm import MultiModalityCausalLM\n",
    "model: MultiModalityCausalLM = MultiModalityCausalLM.from_pretrained(\n",
    "        \"deepseek-ai/Janus-Pro-7B\",\n",
    "        trust_remote_code=True).to(\"cuda\")\n",
    "image = decode_to_pil(input_ids[image_ids_mask].tolist(), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"You are an assistant that creates images from descriptions. First, describe the image in detail, then generate it.\\n\\n<|User|>: 76 best cars coloring pages images on Pinterest Coloring sheets\\n\\n<|Assistant|>: The image is a black and white line drawing of a cartoon-style car. The car has a smiling face with eyes, a nose, and a mouth. It has a rounded body with a small, flat roof. The car is depicted with a single wheel on the front and a single wheel on the back, both of which are simple lines. The car is shown in a side profile, facing to the right. The car has a small, rectangular shape with a slightly curved front. The car is on a flat surface, and there are small, dashed lines indicating the ground beneath it. The style of the image is simple and cartoonish, with clean lines and no shading.<begin_of_image><end_of_image><｜end▁of▁sentence｜>You are an assistant that creates images from descriptions. First, describe the image in detail, then generate it.\\n\\n<|User|>: Healthier 2-Ingredient Peanut Butter Cups - You are going to love this easy peanut butter cup recipe! They're ready in less than 15 minutes (I know, how is this even possible?) and they taste great.\\n\\n<|Assistant|>: The image shows three chocolate-covered peanut butter cups stacked on top of each other. The cups are round with a smooth, glossy chocolate coating. The chocolate appears to be thick and slightly cracked in places, indicating a rich texture. The peanut butter inside is visible through the small opening at the top of each cup. The background is a plain, light gray, which contrasts with the dark chocolate and the creamy peanut butter, making the cups stand out. The style of the image is simple and clean, focusing on the product with a soft, diffused light that highlights the texture and color of the cups.<begin_of_image><end_of_image><｜end▁of▁sentence｜>You are an assistant that creates images from descriptions. First, describe the image in detail, then generate it.\\n\\n<|User|>: Watch the First Trailer for <i>Jobs</i>\\n\\n<|Assistant|>: The image shows a person with short, dark hair and a beard, wearing a light-colored, checkered button-up shirt. The background appears to be an indoor setting with a blurred, neutral-colored wall and a hint of a red object, possibly a candle or a piece of furniture, in the upper right corner. The style of the image is a close-up portrait with a shallow depth of field, focusing on the person's face and upper torso.<begin_of_image><end_of_image><｜end▁of▁sentence｜>You are an assistant that creates images from descriptions. First, describe the image in detail, then generate it.\\n\\n<|User|>: Take a dip in the Venetian Pool\\n\\n<|Assistant|>: The image depicts a Venetian Pool with clear turquoise water. Several people are swimming and lounging on the pool deck. The pool is surrounded by palm trees and a building with a red roof and white walls. The sky is blue with scattered white clouds. The pool deck is made of concrete and has a small island in the middle. The overall style is bright and sunny, suggesting a warm, tropical setting.<begin_of_image><end_of_image><｜end▁of▁sentence｜>\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from janus.models.processing_vlm import VLChatProcessor\n",
    "processor: VLChatProcessor = VLChatProcessor.from_pretrained(\"deepseek-ai/Janus-Pro-7B\")\n",
    "tokenizer = processor.tokenizer\n",
    "text = processor.tokenizer.decode(label_ids[label_text_ids_mask], skip_special_tokens=False)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
